{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4eb1d40b-4aeb-44d5-94d6-ff4c93a1b942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import sympy as sp\n",
    "rc('animation', html='html5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca7b49d5-e8d3-44c4-9309-038fa5469540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "  def __init__(self, w_init=-1.0, b_init=-1.0):\n",
    "    self.W = tf.Variable(w_init)\n",
    "    self.b = tf.Variable(b_init)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.W * x + self.b\n",
    "\n",
    "def loss(target_y, predicted_y):\n",
    "  return tf.reduce_mean(tf.square(target_y - predicted_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b04c2c0-677f-4356-b686-75f650688f66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "SEED = 3141\n",
    "XBOUND_MIN = -30\n",
    "XBOUND_MAX = 30\n",
    "NUM_EXAMPLES = 8194\n",
    "BATCH_SIZE = 268\n",
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea2df6-f475-4d79-8bde-58f53a256f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#user input of the underlying fucntion\n",
    "equation_str = input(\"Enter a linear equation (e.g.,3*x - 5): \")\n",
    "EPOCHS = int(input(\"Enter desired number of epochs for the model: \"))\n",
    "# Define a symbolic variable\n",
    "x = sp.symbols('x')\n",
    "# Parse the input string to create a function\n",
    "try:\n",
    "    equation = sp.sympify(equation_str)\n",
    "    fun = sp.lambdify(x, equation, 'numpy')\n",
    "    slope = equation.as_poly().all_coeffs()[0]\n",
    "    intercept = equation.as_poly().all_coeffs()[1]\n",
    "    \n",
    "except sp.SympifyError:\n",
    "    print(\"Invalid input. Please enter a valid polynomial equation.\")\n",
    "    exit(1)\n",
    "\n",
    "if abs(slope) >= abs(intercept):\n",
    "    bound = float(abs(slope))\n",
    "else:\n",
    "    bound = float(abs(intercept))\n",
    "    \n",
    "#creating data set data loader\n",
    "inputs  = tf.random.normal(shape=[NUM_EXAMPLES], seed=SEED)\n",
    "noise   = tf.random.normal(shape=[NUM_EXAMPLES], seed=SEED+5)\n",
    "outputs = fun(inputs.numpy()) + noise\n",
    "ds = (tf.data.Dataset\n",
    "      .from_tensor_slices((inputs, outputs))\n",
    "      .shuffle(1000, seed=SEED)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .repeat())\n",
    "ds = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "046bd3aa-19b9-4a9e-b197-7fae7ea341ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_regression(title):\n",
    "    model = Model()\n",
    "\n",
    "    # Collect the history of W-values and b-values to plot later\n",
    "    Ws, bs, xs, ys, ls = [], [], [], [], []\n",
    "    initial_loss = 0\n",
    "\n",
    "    fig = plt.figure(dpi=100, figsize=(12, 5))\n",
    "    def init():\n",
    "        return [p10]\n",
    "\n",
    "    def update(epoch):\n",
    "        x, y = next(ds)\n",
    "        y_pred = model(x)\n",
    "        current_loss = loss(y, y_pred)\n",
    "\n",
    "        Ws.append(model.W.numpy())\n",
    "        bs.append(model.b.numpy())\n",
    "        xs.append(x.numpy())\n",
    "        ys.append(y_pred.numpy())\n",
    "        ls.append(current_loss.numpy())\n",
    "        p11.set_data(x.numpy(), y.numpy())\n",
    "        inputs = tf.linspace(XBOUND_MIN, XBOUND_MAX, 30)\n",
    "        p12.set_data(inputs, Ws[-1]*inputs + bs[-1])\n",
    "        p20.set_data(range(epoch), ls)\n",
    "        p30.set_data(range(epoch), Ws)\n",
    "        p31.set_data(range(epoch), bs)    \n",
    "        train(model, x, y, learning_rate=LR)\n",
    "        return p11, p12, p20\n",
    "\n",
    "    # Regression Line\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax1.set_title(\"Fitted Line\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    # ax1.set_xlim(-3, 2.5)\n",
    "    # ax1.set_ylim(-8, 11)\n",
    "    p10, = ax1.plot(inputs, outputs, 'r.', alpha=0.1) # full dataset\n",
    "    p11, = ax1.plot([], [], 'C3.') # batch, color Red\n",
    "    p12, = ax1.plot([], [], 'k') # fitted line, color Black\n",
    "\n",
    "    # Loss\n",
    "    ax2 = fig.add_subplot(132)\n",
    "    ax2.set_title(\"Training Loss\")\n",
    "    ax2.set_xlabel(\"Batches Seen\")\n",
    "    ax2.set_xlim(0, EPOCHS)\n",
    "    ax2.set_ylim(0, 40)\n",
    "    p20, = ax2.plot([], [], 'C0') # color Blue\n",
    "\n",
    "    # Weights\n",
    "    ax3 = fig.add_subplot(133)\n",
    "    ax3.set_title(\"Weights\")\n",
    "    ax3.set_xlabel(\"Batches Seen\")\n",
    "    ax3.set_xlim(0, EPOCHS)\n",
    "    ax3.set_ylim(-(bound+1),bound+1)\n",
    "    ax3.plot(range(EPOCHS), [float(slope) for _ in range(EPOCHS)], 'C5--')\n",
    "    ax3.plot(range(EPOCHS), [float(intercept) for _ in range(EPOCHS)], 'C8--')\n",
    "    p30, = ax3.plot([], [], 'C5') # W color Brown\n",
    "    p30.set_label('Slope')\n",
    "    p31, = ax3.plot([], [], 'C8') # b color Green\n",
    "    p31.set_label('Intercept')\n",
    "    ax3.legend()\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, update, frames=range(1, EPOCHS), init_func=init, blit=True, interval=100)\n",
    "    plt.close()\n",
    "    return anim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67824f42-e22e-40db-842b-06f34639ec34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Linear regression with SGD optimizer\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model(inputs))\n",
    "    gradients = t.gradient(current_loss, [model.W, model.b])   \n",
    "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f8492-edea-4d35-baa0-42d76fe01642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_regression(title = \"Regression using SGD Optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7cf1c-5ef2-4bc9-b8ba-76a38ed2d766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Linear regression with Adam optimizer\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model(inputs))\n",
    "    gradients = t.gradient(current_loss, [model.W, model.b])   \n",
    "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a7224-cdc1-44d9-94a5-873251262194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_regression(title = \"Regression using Adam Optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d0aad-f80f-4e43-9dcd-8c6444be3a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Linear regression with RMSProp optimizer\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model(inputs))\n",
    "    gradients = t.gradient(current_loss, [model.W, model.b])   \n",
    "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de21c3e-8da1-4f18-808f-ae5e3bf30c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_regression(title = \"Regression using RMSProp Optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6462af9-3c80-4ad3-8afe-ac48668e6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression with Adagrad optimizer\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model(inputs))\n",
    "    gradients = t.gradient(current_loss, [model.W, model.b])   \n",
    "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a536c34-588f-47ac-bd14-3b050f03e3a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_regression(title = \"Regression using Adagrad Optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288925d1-6c90-45a3-b26f-3b5cd71fb8eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Linear regression with FTRL optimizer\n",
    "def train(model, inputs, outputs, learning_rate):\n",
    "    optimizer = tf.keras.optimizers.Ftrl(learning_rate=learning_rate)    \n",
    "    with tf.GradientTape() as t:\n",
    "        current_loss = loss(outputs, model(inputs))\n",
    "    gradients = t.gradient(current_loss, [model.W, model.b])   \n",
    "    optimizer.apply_gradients(zip(gradients, [model.W, model.b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6332cac-9523-4da9-a8e1-1b1bc8464202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_regression(title = \"Regression using FTRL Optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435315d9-0168-4feb-9112-de5a40a21c5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##QUADRATIC CURVE FITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d18d8e6-7cbc-4e4c-9ed7-899055f36035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "NUM_EXAMPLES = 9184\n",
    "BATCH_SIZE = 1000\n",
    "EPOCHS = 150 # actually steps\n",
    "LR = 0.01\n",
    "SEED = 6800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59994595-99af-4ad6-9f02-853717890ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Model with SGD\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=LR), \n",
    "    loss='mse')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f4d9f-9699-47a8-a035-e8a1b982708a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "equation_str = input(\"Enter a quadratic equation (e.g: 2*x**2 - 5*x + 8): \")\n",
    "x = sp.symbols('x')\n",
    "try:\n",
    "    equation = sp.sympify(equation_str)\n",
    "    fun = sp.lambdify(x, equation, 'numpy')\n",
    "except sp.SympifyError:\n",
    "    print(\"Invalid input. Please enter a valid polynomial equation.\")\n",
    "    exit(1)\n",
    "#Data for the model\n",
    "inputs  = tf.random.normal(shape=[NUM_EXAMPLES], seed=SEED)\n",
    "noise   = tf.random.normal(shape=[NUM_EXAMPLES], seed=SEED+1)\n",
    "outputs = fun(inputs.numpy()) + noise\n",
    "outputs = tf.squeeze(outputs)\n",
    "ds = (tf.data.Dataset\n",
    "      .from_tensor_slices((inputs, outputs))\n",
    "      .repeat()\n",
    "      .shuffle(1000, seed=SEED)\n",
    "      .batch(BATCH_SIZE))\n",
    "ds = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b01de3-faed-4d17-9f96-f1e33a5cb4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_quad_regression():    \n",
    "    xs, ys, ls = [], [], []\n",
    "    max_loss = 0\n",
    "    fig = plt.figure(dpi=150, figsize=(8, 3))\n",
    "\n",
    "    def init():\n",
    "        return [p10]\n",
    "\n",
    "    def update(epoch):\n",
    "        x, y = next(ds)\n",
    "        y_pred = model(x)\n",
    "        current_loss = model.evaluate(x, y)\n",
    "        x = tf.squeeze(x)\n",
    "        y = tf.squeeze(y)\n",
    "        y_pred = tf.squeeze(y_pred)\n",
    "\n",
    "        xs.append(x.numpy())\n",
    "        ys.append(y_pred.numpy())\n",
    "        ls.append(current_loss)\n",
    "        max_loss = max(ls)\n",
    "        p11.set_data(x.numpy(), y.numpy())\n",
    "        inputs = tf.linspace(-3.0, 3.0, 30)\n",
    "        p12.set_data(inputs, model.predict(inputs))\n",
    "        p20.set_data(range(epoch), ls)\n",
    "        model.train_on_batch(x, y)\n",
    "        return p11, p12, p20\n",
    "\n",
    "    # Regression Curve\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.set_title(\"Fitted Curve With Adam\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    p10, = ax1.plot(inputs, outputs, 'r.', alpha=0.1) # full dataset\n",
    "    p11, = ax1.plot([], [], 'C3.') # batch\n",
    "    p12, = ax1.plot([], [], 'k') # fitted line\n",
    "\n",
    "    # Loss\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.set_title(\"Training Loss\")\n",
    "    ax2.set_xlabel(\"Batches Seen\")\n",
    "    ax2.set_xlim(0, EPOCHS)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    p20, = ax2.plot([], [], 'C0')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    anim = animation.FuncAnimation(fig, update, frames=range(1, EPOCHS), init_func=init, blit=True, interval=100)\n",
    "    plt.close()\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9fbb8-95cd-4cc4-8fe7-d77015c255c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_quad_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "408c04fa-421f-47eb-a2ae-c344ecd8da45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Model with Adam\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(1,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LR), \n",
    "    loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd2a90a-7c4b-4df3-8832-1b8f617e006c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_quad_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d594e3-ebf0-4bcb-9bf4-798503e22de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
